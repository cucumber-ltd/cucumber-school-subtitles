1
00:00:14,660 --> 00:00:17,920
Welcome to the final lesson in
this series of Cucumber School

2
00:00:18,480 --> 00:00:21,700
Over the series we've tried to cover
all the important techniques

3
00:00:21,700 --> 00:00:27,140
and concepts we think you need to become a
successful behaviour-driven developer

4
00:00:28,140 --> 00:00:32,080
We've taught you how to break down
requirements with example mapping

5
00:00:32,080 --> 00:00:35,580
and how to express those examples
as Gherkin scenarios

6
00:00:36,100 --> 00:00:39,960
We've explained the importance of
keeping your features readable

7
00:00:39,960 --> 00:00:44,580
and shown you how to write great, flexible
step definitions to help you achieve that goal

8
00:00:45,820 --> 00:00:50,780
We've also explored the difference between
acceptance tests and unit tests

9
00:00:50,780 --> 00:00:55,460
and demonstrated how the outside in
approach to software development works

10
00:00:55,460 --> 00:00:58,100
using both types of tests
to drive out the solution to your

11
00:00:58,100 --> 00:00:59,640
stakeholders' problems

12
00:01:01,640 --> 00:01:04,820
One glaring omission from
the story so far however

13
00:01:04,820 --> 00:01:08,340
is that our Shouty solution is
nothing more than a domain model

14
00:01:09,320 --> 00:01:12,280
It doesn't have any way for
a user to interact with it

15
00:01:12,960 --> 00:01:15,780
Well, that's all about to change

16
00:01:16,540 --> 00:01:19,800
In this episode, we'll review the code
that's just been written

17
00:01:19,800 --> 00:01:23,720
for the first iteration of
Shouty's web user interface

18
00:01:23,720 --> 00:01:27,420
and show you how to use Selenium WebDriver

19
00:01:27,420 --> 00:01:33,440
a browser automation library to run our
Cucumber scenarios through that user interface

20
00:01:34,460 --> 00:01:38,520
We think it would be irresponsible
to teach you how to use Selenium

21
00:01:38,520 --> 00:01:44,060
without also teaching you about the Agile
testing pyramid and its nemesis

22
00:01:44,060 --> 00:01:45,980
the testing ice cream cone

23
00:01:46,760 --> 00:01:50,120
We've come across too many teams
who have ended up with

24
00:01:50,120 --> 00:01:55,820
miserably slow, unreliable test suites
that cost too much to maintain

25
00:01:55,820 --> 00:01:59,300
because all their Cucumber scenarios
go through the UI

26
00:02:00,060 --> 00:02:03,600
It doesn't have to be this way
and in this episode

27
00:02:03,600 --> 00:02:05,760
we'll show you how to avoid this trap

28
00:02:06,760 --> 00:02:10,560
Let's start by walking you through
the changes that have been happening

29
00:02:10,560 --> 00:02:13,060
in the code base while we've been away

30
00:02:13,640 --> 00:02:16,480
Shouty now has a simple web UI

31
00:02:16,480 --> 00:02:19,340
which displays a form
where a user can shout a message

32
00:02:20,440 --> 00:02:24,680
It won't win any awards for style just yet
but it should be functional at least

33
00:02:26,300 --> 00:02:29,780
We can let Cucumber put the new web app
through its paces

34
00:02:29,780 --> 00:02:35,180
by setting the shouty_test_depth
environment variable to web

35
00:02:35,180 --> 00:02:36,700
when we run Cucumber

36
00:02:37,840 --> 00:02:43,320
This setting causes the scenarios
to be run through the browser via Selenium

37
00:02:43,320 --> 00:02:45,040
and if you watch closely

38
00:02:45,040 --> 00:02:48,440
you can see the message being typed
into the form as it runs

39
00:02:50,000 --> 00:02:53,560
You can see it's way slower
to run the scenarios via browser

40
00:02:53,980 --> 00:02:55,020
Around a minute!

41
00:03:21.472 --> 00:03:25.800
Luckily, we still have our original
much faster version of the acceptance tests

42
00:03:25.800 --> 00:03:27.616
that go directly to the domain model

43
00:03:28.384 --> 00:03:30.432
These run in less than a second

44
00:03:31.200 --> 00:03:35.600
We can run this version by setting
shouty.testDepth to something else

45
00:03:35.600 --> 00:03:37.856
or just leaving it out altogether

46
00:03:39.250 --> 00:03:40.700
Nice!

47
00:03:40.700 --> 00:03:43.488
So we have the best of both worlds it seems

48
00:03:44.300 --> 00:03:48.096
Let's have a look at how this
has been implemented in the features

49
00:03:49.500 --> 00:03:54.496
In this world.rb file here
we now have two separate modules being defined

50
00:03:54.752 --> 00:03:58.750
Our original ShoutyWorld has been
renamed to DomainWorld

51
00:03:58.750 --> 00:04:01.664
and a new WebWorld has been added

52
00:03:54.752 --> 00:03:58.750
WebWorld has exactly the same
methods as the original DomainWorld

54
00:03:58.750 --> 00:04:01.664
and a new WebWorld has been added

55
00:04:02.176 --> 00:04:06.350
WebWorld has exactly the same
methods as the original DomainWorld

56
00:04:06.350 --> 00:04:08.832
but the implementation is quite different

57
00:04:09.856 --> 00:04:11.500
In the sean_shout method

58
00:04:11.500 --> 00:04:16.400
rather than calling the Person domain object
directly to shout the message

59
00:04:16.400 --> 00:04:21.300
the WebWorld calls this visit method
to open the homepage as Sean

60
00:04:21.300 --> 00:04:24.000
then posts the message into
the shout form

61
00:04:25.000 --> 00:04:29.823
Where have these new methods
visit, fill_in, and click_button come from?

62
00:04:30.847 --> 00:04:32.800
They're provided by Capybara

63
00:04:32.800 --> 00:04:36.300
which is a delightful Ruby library
that wraps Selenium WebDriver

63
00:04:36.300 --> 00:04:38.527
in a user-friendly package

64
00:04:39.039 --> 00:04:41.750
I know you're almost drowning
in buzzwords at this point

65
00:04:41.750 --> 00:04:45.000
Don't worry- we'll clear up this in a moment

66
00:04:45.000 --> 00:04:46.800
Let's continue with the tour

00:04:48.150 --> 00:04:52.607
Down here, we examine the value of
the 'shouty_test_depth' environment variable

68
00:04:52.863 --> 00:04:54.250
If it's 'web'

69
00:04:54.250 --> 00:04:58.751
we load Capybara, configure it for Selenium,
tell it how to boot up our web app

70
00:04:59.263 --> 00:05:04.127
then finally, tell Cucumber to use
the WebWorld in the step definitions

71
00:05:05.151 --> 00:05:09.500
The alternative, of course,
is just to use the DomainWorld as normal

72
00:05:09.500 --> 00:05:13.599
Let's walk through what happens
when a scenario runs using the WebWorld

73
00:05:14.200 --> 00:05:18.500
When Cucumber runs the
'Sean shouts, "Free bagels!"' step

74
00:05:18.500 --> 00:05:22.559
it searches for the corresponding
step definition and executes it

75
00:05:23.350 --> 00:05:28.750
Now, the code in that step definition
calls the sean_shout method on the World

76
00:05:28.750 --> 00:05:34.079
which in turn calls the visit method
on Capybara to open the homepage as Sean

78
00:05:59,420 --> 00:06:02,900
When Cucumber runs the
'Sean shouts Free Bagels' step

79
00:06:02,900 --> 00:06:07,620
it searches for the corresponding step definition
and executes the method in the StepDefs class

80
00:06:09,160 --> 00:06:14,780
Now, the code in that step definition calls
the seanShout method on shoutSupport

81
00:06:14,780 --> 00:06:18,520
which is an instance of WebShoutSupport

82
00:06:18,520 --> 00:06:20,780
which in turn creates a WebDriver

83
00:06:20,780 --> 00:06:24,760
and calls the get method on it to
open the homepage as Sean

84
00:06:25,460 --> 00:06:29,680
Selenium WebDriver now tells Firefox to
open a browser at that URL

85
00:06:29,680 --> 00:06:34,240
and when the browser opens that URL
our web server will get a request for the page

86
00:06:34,740 --> 00:06:37,820
We render the page on the server
and the browser displays it

87
00:06:38,840 --> 00:06:43,920
Next, WebShoutSupport asks Selenium to fill out
and submit the shout form

88
00:06:43,920 --> 00:06:46,340
which causes button clicks in the browser

89
00:06:47,300 --> 00:06:51,020
The form is submitted to the server
and the server calls the core domain

90
00:06:51,020 --> 00:06:52,420
to broadcast the shout

91
00:06:53,900 --> 00:07:00,360
In contrast, domainShoutSupport’s implementation
of seanShout calls the domain model directly

92
00:07:01,120 --> 00:07:04,960
Notice this is exactly the same code
as the web server uses

93
00:07:05,660 --> 00:07:08,740
The strategy that talks directly
to the core domain model

94
00:07:08,740 --> 00:07:11,480
gives us fast feedback
and lets us test where the

95
00:07:11,480 --> 00:07:14,220
heart of the application's behaviour
is implemented

96
00:07:14,940 --> 00:07:18,440
We've now added a second strategy
that allows us to prove this behavior

97
00:07:18,440 --> 00:07:21,080
still works when presented via the web UI

98
00:07:22,111 --> 00:07:24,159
You might be wondering why we need both?

99
00:07:24,680 --> 00:07:28,520
Why didn't we just start driving our way in
from the web UI in the beginning?

100
00:07:30,360 --> 00:07:36,140
We've found that focusing on driving out
a domain model from our scenarios first

101
00:07:36,140 --> 00:07:38,420
modelling by example

102
00:07:38,420 --> 00:07:42,600
gives us fast feedback about
our understanding of new problem domains

103
00:07:43,220 --> 00:07:46,500
We don't get distracted by
solution domain complexities like

104
00:07:46,500 --> 00:07:49,500
web servers, HTML, and so on

105
00:07:49,500 --> 00:07:53,080
while we're still just trying to understand
the core of the problem

106
00:07:54,500 --> 00:07:58,580
In the long run, we also find that
staying focused on the core domain

107
00:07:58,580 --> 00:08:02,040
helps us build scenarios that are
more stable over time

108
00:08:03,080 --> 00:08:05,980
User interfaces tend to change
a lot more often

109
00:08:05,980 --> 00:08:08,700
than the core business rules of the domain

110
00:08:10,500 --> 00:08:14,500
Building scenarios that make sense
even without a user interface

111
00:08:14,500 --> 00:08:17,680
also helps us to avoid
our tests from becoming too

112
00:08:17,680 --> 00:08:18,940
Imperative

113
00:08:19,960 --> 00:08:23,660
Most teams who write and run their cukes
against the user interface

114
00:08:23,660 --> 00:08:29,180
end it with a lot of incidental detail
in their scenarios about the UI interaction

115
00:08:29,695 --> 00:08:31,231
Solution domain stuff

116
00:08:31,999 --> 00:08:34,559
These scenarios are poor documentation

117
00:08:35,080 --> 00:08:38,820
They're too busy talking about
how the user performs a task

118
00:08:38,820 --> 00:08:41,760
rather than what the user is trying to achieve

119
00:08:42,760 --> 00:08:46,420
For example we might have written
the scenario like this instead

120
00:08:50,260 --> 00:08:53,000
This scenario doesn't illustrate
the behaviour very well

121
00:08:53,760 --> 00:08:57,360
If you didn't know anything about Shouty
and were trying to understand it

122
00:08:57,360 --> 00:09:00,920
through the examples written like this
you'd have a tough time

123
00:09:01,740 --> 00:09:04,040
It makes for lousy documentation

124
00:09:05,540 --> 00:09:11,440
Notice how the language used in this scenario
the URLs, the CSS selectors

125
00:09:11,440 --> 00:09:14,360
even the filling in fields
and clicking of buttons

126
00:09:14,360 --> 00:09:17,560
is from the solution domain
not the problem domain

127
00:09:18,335 --> 00:09:22,175
It tells you nothing about
your team's ubiquitous language

128
00:09:23,960 --> 00:09:26,900
Finally, this scenario is brittle

129
00:09:26,900 --> 00:09:31,200
If you need to change the details
of the interaction for sending a shout

130
00:09:31,200 --> 00:09:33,340
such as the way you authenticate

131
00:09:33,340 --> 00:09:36,760
you'd need to come back
and change every scenario that involves shouting

132
00:09:37,535 --> 00:09:43,935
By pushing the how down
your scenarios will remain truer for longer

133
00:09:44,700 --> 00:09:48,060
The opposite of the imperative style
where we express the scenarios

134
00:09:48,060 --> 00:09:51,160
using problem domain language is known as a

135
00:09:51,160 --> 00:09:52,640
Declarative Style

136
00:09:53,340 --> 00:09:57,540
In this style, we try to describe
what the user is trying to achieve

137
00:09:57,540 --> 00:09:59,520
rather than how they do it

138
00:10:00,840 --> 00:10:04,640
Thanks to the declarative style
we've been using through the rest of the series

139
00:10:04,640 --> 00:10:07,980
we were able to easily swap in a
different strategy for automating

140
00:10:07,980 --> 00:10:12,100
our application through the web
without changing our specifications

141
00:10:13,120 --> 00:10:18,900
If there are other interfaces to our application
like a rest API or a mobile app

142
00:10:18,900 --> 00:10:22,300
we can continue to use this pattern
adding new strategies

143
00:10:22,300 --> 00:10:25,660
that run our scenarios through
these new layers of the stack

144
00:10:26,940 --> 00:10:33,400
Remember, each of these strategies uses
exactly the same scenarios and step definitions

145
00:10:34,520 --> 00:10:40,120
This means the investment you put into
writing your scenarios pays back over and over

146
00:10:40,120 --> 00:10:43,160
as you reuse them to validate
the behaviour of the application

147
00:10:43,160 --> 00:10:44,820
from these different perspectives

148
00:10:45,640 --> 00:10:49,880
This is a major advantage of having
pushed the details of how Sean shouts

149
00:10:49,880 --> 00:10:51,260
down into a helper method

150
00:10:52,040 --> 00:10:54,780
If this detail was still up
in the step definition

151
00:10:54,780 --> 00:10:59,720
or worse, in the scenario itself
we wouldn't have this flexibility

152
00:11:02,020 --> 00:11:05,560
In general, the structure emerging
in our application and test code

153
00:11:05,560 --> 00:11:09,200
is called a ports and adapters architecture, or

154
00:11:09,200 --> 00:11:10,900
Hexagonal Architecture

155
00:11:11,740 --> 00:11:14,640
You can think of ports and adapters
as a direct analogy

156
00:11:14,640 --> 00:11:17,380
to physical devices with plugs and sockets

157
00:11:18,140 --> 00:11:21,320
For example, the HDMI port on this laptop

158
00:11:21,320 --> 00:11:24,900
lets me plug in any kind of display
that also has a HDMI port

159
00:11:25,840 --> 00:11:30,420
If I need to use a VGA display
I can use an adapter between the two

160
00:11:31,720 --> 00:11:34,140
In a hexagonal architecture

161
00:11:34,140 --> 00:11:37,340
the inner hexagon contains
your core business logic

162
00:11:38,340 --> 00:11:42,360
This is where the if statements that
deliver the most value to your stakeholders

163
00:11:42,360 --> 00:11:43,240
should live

164
00:11:44,460 --> 00:11:47,160
The inner hexagon knows nothing about
the outside world:

165
00:11:47,160 --> 00:11:52,700
your web servers, your databases, your email
sending service, or your enterprise message bus

166
00:11:53,400 --> 00:11:55,660
It's pure business logic

167
00:11:56,740 --> 00:12:00,860
We expose this core behavior via
one or more ports

168
00:12:01,660 --> 00:12:05,760
A port is really just a protocol
an API if you like

169
00:12:06,280 --> 00:12:10,760
Any component who understands that protocol
can then plug in and interact

170
00:12:10,760 --> 00:12:12,600
with the core through the port

171
00:12:13,700 --> 00:12:15,900
We call that component an adapter

172
00:12:16,440 --> 00:12:21,120
It's the adapter's job to expose
the core domain logic to the outside world

173
00:12:23,680 --> 00:12:26,580
In Shouty, there's just one port

174
00:12:26,580 --> 00:12:30,860
the API to our domain model
made up of the Person and Network classes

175
00:12:31,840 --> 00:12:35,200
We've plugged in two different adapters
to this little port:

176
00:12:35,200 --> 00:12:38,840
the WebApp, which exposes
Shouty's core domain over the web

177
00:12:38,840 --> 00:12:42,220
for users (or Selenium WebDriver)
to interact with

178
00:12:43,140 --> 00:12:45,360
And DomainShoutSupport

179
00:12:45,360 --> 00:12:48,000
which lets Cucumber
drive the application directly

180
00:12:48,767 --> 00:12:51,839
Both are clients of the same API

181
00:12:54,140 --> 00:12:59,000
The hexagonal architecture is a terrific fit
for teams who care about testability

182
00:12:59,560 --> 00:13:03,020
In fact, it was invented precisely
to allow for testability

183
00:13:03,020 --> 00:13:07,200
back in the days when thick client GUIs
were impossible to automate

184
00:13:07,900 --> 00:13:11,040
By separating the core domain logic from the GUI

185
00:13:11,040 --> 00:13:16,500
these TDD pioneers were able to plug
their tests into the same port as the GUI

186
00:13:16,500 --> 00:13:19,500
and still test most of
the application's behaviour

187
00:13:20,760 --> 00:13:24,320
If you have the discipline
to keep your code separated like this

188
00:13:24,320 --> 00:13:26,160
you benefit from being able to
run the tests

189
00:13:26,160 --> 00:13:30,120
against the most business-valuable
lines of code in your codebase

190
00:13:30,120 --> 00:13:33,820
the core domain
in the shortest amount of time

191
00:13:35,100 --> 00:13:38,920
Tests that hit pure business logic
can run lightning fast

192
00:13:38,920 --> 00:13:41,860
meaning it's cheap to get
really thorough feedback

193
00:13:41,860 --> 00:13:44,580
about whether that logic is behaving correctly

194
00:13:45,860 --> 00:13:47,400
Let's get back to the code

195
00:13:48,100 --> 00:13:52,620
To give us a way to test the app manually
the Shouty developers have kindly added this

196
00:13:52,620 --> 00:13:54,720
ManualTestServer class

197
00:13:54,720 --> 00:13:58,400
which starts the web server pre-configured
with some familiar test data

198
00:13:59,420 --> 00:14:01,500
This means we're able to
test the web app

199
00:14:01,500 --> 00:14:05,560
without having to create accounts for people -
a feature we don't have yet!

200
00:14:06,960 --> 00:14:10,660
So we should be able to
open our browser tab as Sean

201
00:14:10,660 --> 00:14:15,100
then another tab as Lucy
send a shout from Sean

202
00:14:15,100 --> 00:14:21,180
refresh Lucy's page and see- 
wait a minute! Where's Sean Shout?

203
00:14:22,460 --> 00:14:23,900
This is odd -

204
00:14:23,900 --> 00:14:28,860
The scenario is passing
but there's nothing appearing on Lucy's page

205
00:14:29,887 --> 00:14:31,167
What's going on?

206
00:14:32,959 --> 00:14:37,311
The answer lies in the implementation
of our Then step

207
00:14:38,600 --> 00:14:41,340
Reading it, we can see that
the step definition

208
00:14:41,340 --> 00:14:44,700
is going directly to the domain model
to discover the messages

209
00:14:44,700 --> 00:14:46,020
that Lucy has heard

210
00:14:47,200 --> 00:14:51,660
This shouldn't have been a surprise to us -
it's always been that way -

211
00:14:51,660 --> 00:14:57,100
but since our When step now hits the UI
we would expect this Then step

212
00:14:57,100 --> 00:14:59,320
to also adopt the same strategy

213
00:15:00,940 --> 00:15:05,040
When you start to mix different
depths of testing as we’re doing here

214
00:15:05,040 --> 00:15:10,600
a good rule of thumb is to keep the depth of your
When and Then steps consistent

215
00:15:11,780 --> 00:15:15,800
It’s often advisable to bypass layers
and reach down deeper into the stack

216
00:15:15,800 --> 00:15:18,780
to set up state in the Given steps

217
00:15:19,580 --> 00:15:22,740
But if we carry out an action via the UI

218
00:15:22,740 --> 00:15:27,220
the outcome check in the Then step
should also be done through the UI

219
00:15:29,540 --> 00:15:34,100
Let’s remedy this situation by
pushing the code in this step definition

220
00:15:34,100 --> 00:15:35,420
into a helper method

221
00:15:36,460 --> 00:15:38,060
Then we’ll be able to have
two different strategies

222
00:15:38,060 --> 00:15:40,540
for checking the messages
that a user has heard

223
00:15:41,840 --> 00:15:44,840
Once we have a failing test for
the web strategy

224
00:15:44,840 --> 00:15:49,240
we can drive out the behaviour in the UI
to display the user’s messages

225
00:15:50,280 --> 00:15:53,100
We’ll focus on a single scenario
while we do this work

226
00:15:54,020 --> 00:15:57,440
Once we’ve got that one passing
to our satisfaction

227
00:15:57,440 --> 00:16:00,520
we can apply the same change across
the rest of the scenarios

228
00:16:01,800 --> 00:16:06,920
This very basic scenario, where Lucy hears Sean
is a good place to start

229
00:16:10,380 --> 00:16:15,700
Let's extract a method, getMessagesHeardBy
from the body of the step definition

230
00:16:15,700 --> 00:16:18,440
and put it in our DomainShoutSupport

231
00:16:30,220 --> 00:16:32,080
That scenario is still passing

232
00:16:32,620 --> 00:16:33,140
Good

233
00:16:34,360 --> 00:16:36,360
Now, when we run it through the web

234
00:16:36,360 --> 00:16:39,040
we’re shown we need to add
that method to WebShoutSupport

235
00:16:40,520 --> 00:16:42,560
How will we fetch the messages heard?

236
00:16:45,820 --> 00:16:47,680
The first thing we’ll need to do is log in

237
00:16:47,680 --> 00:16:50,180
to make sure we’re reading the messages
for the correct user

238
00:16:50,687 --> 00:16:53,247
So we can re-use this
helper method we’ve already built

239
00:16:54,527 --> 00:16:58,111
Now, we’ll need to
scrape the messages off the HTML page

240
00:16:59,135 --> 00:17:02,719
Remember we’re going test-first here
so we don’t have this markup yet

241
00:17:03,480 --> 00:17:04,800
That's not a problem

242
00:17:04,800 --> 00:17:08,600
We can use the test to help us design
what the markup should look like

243
00:17:10,140 --> 00:17:15,000
Let’s assume that each message will be
an element with a message class on it

244
00:17:16,100 --> 00:17:19,680
We can ask Selenium to give us all
the elements with that class

245
00:17:20,640 --> 00:17:24,220
That gives us a list of
Selenium WebDriver Elements

246
00:17:24,220 --> 00:17:27,560
which we can then transform into
a list of their text content

247
00:17:35,120 --> 00:17:36,660
Let's watch this test fail

248
00:17:40,640 --> 00:17:41,660
That looks OK.

249
00:17:42,600 --> 00:17:44,640
Let's play fake it till you make it

250
00:17:44,640 --> 00:17:47,260
just to check this assertion
is doing the right thing

251
00:17:47,780 --> 00:17:51,620
We’ll hard-code the HTML we want
into the template, here

252
00:17:53,300 --> 00:17:56,220
This gives us a chance to
talk with our designer about the markup

253
00:17:57,260 --> 00:18:01,860
We go over for a chat and he loves it
so we can press on!

254
00:18:08,340 --> 00:18:12,200
The next step is to
make the HTML template dynamic

255
00:18:12,200 --> 00:18:15,940
and have it display the actual list of
messages heard by the user

256
00:18:16,700 --> 00:18:20,540
We could continue using the
Cucumber scenario to drive this out

257
00:18:20,540 --> 00:18:25,160
but it would be better to zoom in and focus
on some unit tests for the web app now

258
00:18:26,180 --> 00:18:29,740
That way, if this behaviour ever
slips loose in the future

259
00:18:29,740 --> 00:18:33,600
there will be a unit test pointing us
to exactly where we need to go to fix it

260
00:18:34,879 --> 00:18:38,975
Luckily, the web app has already been built
with some unit tests around it

261
00:18:40,260 --> 00:18:47,520
These tests load the HttpServlet in isolation
passing in a map of people

262
00:18:47,520 --> 00:18:49,720
that just contains test doubles

263
00:18:50,400 --> 00:18:53,720
We could have used real instances
from our core domain model

264
00:18:53,720 --> 00:18:57,780
but as we explained in the last episode
using test doubles helps us to see

265
00:18:57,780 --> 00:19:02,360
the protocol on the port between the web app
adapter and our core domain

266
00:19:03,660 --> 00:19:08,140
We’ve abstracted some of the nitty-gritty
of calling the Servlet into a base class

267
00:19:08,140 --> 00:19:09,960
which you can examine for yourself

268
00:19:15,583 --> 00:19:19,727
We need a new test for the GET request
which simulates the situation where

269
00:19:19,727 --> 00:19:22,520
Lucy has heard a couple of messages

270
00:19:23,000 --> 00:19:24,520
and views her homepage

271
00:19:44,000 --> 00:19:48,100
We’d expect to be able to find the message text
in each of the message elements

272
00:19:54,751 --> 00:19:59,871
When we run this, it fails because
we’re just hard-coding the message at the moment

273
00:20:00,380 --> 00:20:02,180
Let’s TDD our solution

274
00:20:04,440 --> 00:20:07,580
If you’d like to try this yourself
just pause the video here and

275
00:20:07,580 --> 00:20:10,660
see if you can figure out what to do next
before we show you

276
00:20:12,920 --> 00:20:18,900
Starting in the template, we can look for
a local variable, let’s call it messagesHeard

277
00:20:18,900 --> 00:20:20,740
and iterate over it

278
00:20:20,740 --> 00:20:23,420
For each message, we’ll write a message element

279
00:20:24,920 --> 00:20:25,580
There

280
00:20:26,500 --> 00:20:30,160
Now we need to set that messagesHeard
variable for the template

281
00:20:30,160 --> 00:20:34,680
We do that from within the doGet request handler
method in the web servlet

282
00:20:35,967 --> 00:20:39,551
We need to put the messagesHeard into this context map

283
00:20:40,320 --> 00:20:45,340
Helpfully we have this getUser method that
fetches the right user from the people map

284
00:20:45,340 --> 00:20:48,620
based on the query string parameter used in the request

285
00:20:48,620 --> 00:20:50,040
Let’s give that a try

286
00:20:51,583 --> 00:20:55,679
Great! Suddenly everything is green

287
00:20:56,960 --> 00:21:02,180
Try a quick manual test for yourself
creating a couple of tabs as Sean and Lucy

288
00:21:02,180 --> 00:21:04,900
and satisfy yourself that it’s working now

289
00:21:05,880 --> 00:21:08,280
Now that we’ve proved our
getMessagesHeardBy method

290
00:21:08,280 --> 00:21:11,120
works for both domain and web strategies

291
00:21:11,120 --> 00:21:14,140
let’s use that method in
all the step definitions

292
00:21:14,140 --> 00:21:17,280
so that every scenario
that checks for messagesHeard

293
00:21:17,280 --> 00:21:19,820
will do that check in a consistent way

294
00:21:20,920 --> 00:21:26,040
This is just a matter of finding each call
to ask a Person domain object for messagesHeard

295
00:21:26,040 --> 00:21:28,700
and converting it to use
our new helper method instead

296
00:21:32,160 --> 00:21:34,720
Let's run all the scenarios in the shout feature

297
00:21:48,920 --> 00:21:51,740
Great. It looks like we're done

298
00:21:52,520 --> 00:21:56,020
If we look at the other feature
Premium accounts

299
00:21:56,020 --> 00:21:59,580
we can see that there’s
a similar problem to the one we’ve just resolved

300
00:22:00,320 --> 00:22:05,300
This last step
'Then Sean should have n credits'

301
00:22:05,300 --> 00:22:08,520
goes direct to the domain model
to check Sean’s credits

302
00:22:08,520 --> 00:22:11,260
rather than having that
extra layer of indirection

303
00:22:11,260 --> 00:22:14,780
that would allow us to use a domain
or a web strategy for the check

304
00:22:15,800 --> 00:22:19,120
It will be useful practice for you
to go through and apply

305
00:22:19,120 --> 00:22:22,100
exactly what we just did to this step definition

306
00:22:23,100 --> 00:22:25,400
We'll leave that as an exercise for you

307
00:22:27,460 --> 00:22:29,760
Let's fast-forward to the point
where this is done

308
00:22:31,160 --> 00:22:35,040
Now, we can run all of our scenarios
at both levels

309
00:22:35,040 --> 00:22:38,340
against the domain, and against the web UI

310
00:22:39,620 --> 00:22:41,160
This is awesome!

311
00:22:42,540 --> 00:22:43,840
Isn't it?

312
00:22:43,840 --> 00:22:48,080
We've talked a lot about the benefits of
automated tests in this series

313
00:22:48,080 --> 00:22:51,900
but let’s consider the flip side for a moment
and look at the costs

314
00:22:53,440 --> 00:22:57,280
Every automated test in your system
comes at a cost

315
00:22:58,040 --> 00:23:01,060
You have the cost of 
writing it in the first place

316
00:23:01,060 --> 00:23:04,420
the cost of waiting for it to run each time

317
00:23:04,420 --> 00:23:09,200
the cost of changing it when the
desired behaviour of the application changes

318
00:23:09,200 --> 00:23:13,420
and the cost of debugging it
when it fails for no good reason

319
00:23:15,020 --> 00:23:18,840
When the majority of your tests hit
the application through the user interface

320
00:23:18,840 --> 00:23:20,840
you get a great benefit

321
00:23:20,840 --> 00:23:24,920
from knowing that each scenario
is using the system exactly as a user would

322
00:23:25,980 --> 00:23:29,900
Yet the downside is that
these tests are much slower to run

323
00:23:29,900 --> 00:23:31,840
and are often also much less reliable

324
00:23:33,376 --> 00:23:37,008
A well-known metaphor to help you
think about this problem is the

325
00:23:37,008 --> 00:23:39,008
Agile Testing Pyramid

326
00:23:40,040 --> 00:23:44,760
At the base of the pyramid
you have a large number of unit tests

327
00:23:44,760 --> 00:23:51,180
shallow tests that directly hit isolated
individual classes and modules in your solution

328
00:23:52,840 --> 00:23:59,300
The pyramid gets narrower as you go up
indicating that as the depth of tests increases

329
00:23:59,300 --> 00:24:01,040
the less of them you should have

330
00:24:01,740 --> 00:24:05,160
At the very top of the pyramid
where the tests go right through

331
00:24:05,160 --> 00:24:07,740
the whole application stack

332
00:24:07,740 --> 00:24:09,480
you want as few as possible

333
00:24:10,440 --> 00:24:13,820
Just enough to give you confidence
the thing is working

334
00:24:15,620 --> 00:24:18,720
When you drive most of
your behaviour through the GUI

335
00:24:18,720 --> 00:24:23,280
you end up with the opposite -
more of a testing ice cream cone

336
00:24:24,060 --> 00:24:29,620
Now I love an ice cream on a hot summer’s day
but when your test suite looks like this

337
00:24:29,620 --> 00:24:33,640
you’re waiting hours for test results
and there are generally at least

338
00:24:33,640 --> 00:24:37,120
one or two random failures in every build

339
00:24:40,960 --> 00:24:44,560
Although we have the choice to
run every Shouty scenario through the GUI

340
00:24:44,560 --> 00:24:48,720
the Agile Testing Pyramid tells us
that would be a bad idea

341
00:24:49,840 --> 00:24:56,100
We need to select a few representative or
key examples to run through the web UI

342
00:24:56,100 --> 00:24:58,360
and run the rest through the domain

343
00:24:59,392 --> 00:25:01,440
How do we choose those key examples?

344
00:25:02,976 --> 00:25:05,792
Let’s try and think about
what could possibly go wrong

345
00:25:06,560 --> 00:25:10,040
We want to identify the minimum number of
scenarios that would give us confidence

346
00:25:10,040 --> 00:25:11,420
the system is working

347
00:25:12,120 --> 00:25:15,280
Remember: both our core domain
and our web server

348
00:25:15,280 --> 00:25:17,660
are protected by their own unit tests

349
00:25:17,660 --> 00:25:20,380
so we just need a few checks
for basic correctness

350
00:25:21,000 --> 00:25:26,280
Would it be enough to just test this scenario
the one where the listener is within range?

351
00:25:27,296 --> 00:25:30,112
If we did that, what could possibly go wrong?

352
00:25:31,640 --> 00:25:34,340
With our tester’s hat on
we can imagine a bug

353
00:25:34,340 --> 00:25:37,800
where the web server’s template
didn’t render multiple messages

354
00:25:38,660 --> 00:25:40,700
This scenario only works for one

355
00:25:41,640 --> 00:25:45,480
So we could add this scenario
the one where there are two shouts

356
00:25:46,240 --> 00:25:49,128
Yet we’d easily catch that bug in manual testing

357
00:25:49,128 --> 00:25:52,128
and could then pin it down with
a unit test on the web server

358
00:25:53,408 --> 00:25:56,736
So we don’t need to run this as a
full-stack test every time

359
00:25:57,500 --> 00:25:58,840
In fact

360
00:25:58,840 --> 00:26:01,340
to do so would be wasteful

361
00:26:03,140 --> 00:26:06,720
How about the scenario about
the listener being out of range?

362
00:26:07,540 --> 00:26:10,980
If we skip that in our web-depth Cucumber run

363
00:26:10,980 --> 00:26:13,900
would we leave ourselves vulnerable
to a dangerous bug?

364
00:26:15,420 --> 00:26:19,240
Well, it’s true that if people heard messages
that were not meant for them

365
00:26:19,240 --> 00:26:21,560
it could make us look pretty bad

366
00:26:22,592 --> 00:26:24,640
But how likely is this to happen?

367
00:26:25,400 --> 00:26:28,120
That logic is all in the core domain

368
00:26:28,120 --> 00:26:31,540
the web server just renders
the messages returned by the core

369
00:26:32,320 --> 00:26:35,904
So there’s almost a zero risk of
this bug ever leaking out

370
00:26:36,672 --> 00:26:40,256
Again, a full-stack test for this
behaviour would be wasteful

371
00:26:42,820 --> 00:26:45,820
Although the same goes for
the logic about a long message

372
00:26:45,820 --> 00:26:49,300
we know that there’s potential for
there to be bugs in the interaction

373
00:26:49,300 --> 00:26:51,880
of the UI for longer messages

374
00:26:51,880 --> 00:26:53,820
so it makes sense for us to run this one

375
00:26:54,600 --> 00:26:57,500
Let’s mark it up as @high-risk

376
00:26:57,500 --> 00:27:01,400
and mark the one where the listener is
within range as @high-impact

377
00:27:02,280 --> 00:27:04,080
We’ll explain these terms in a moment

378
00:27:05,440 --> 00:27:12,260
Now, we can run the tests at the top of our pyramid
using those tags and the web testDepth setting

379
00:27:13,280 --> 00:27:17,800
Now we have three different levels of tests in
our pyramid that we want to run to check our code

380
00:27:18,440 --> 00:27:19,940
The unit tests

381
00:27:19,940 --> 00:27:25,300
the core domain acceptance tests
and the key examples running as full-stack tests

382
00:27:27,360 --> 00:27:31,960
Let's set up our maven configuration to run
all of these tests first with a single command

383
00:27:33,520 --> 00:27:37,260
Maven already runs our unit and domain-level
acceptance tests automatically

384
00:27:37,260 --> 00:27:38,880
using the surefire plugin

385
00:27:39,600 --> 00:27:44,440
We can add extra configuration to our pom.xml
to tell surefire to run a second execution

386
00:27:44,440 --> 00:27:47,080
of the tests with different configuration

387
00:27:48,352 --> 00:27:50,912
Just add a surefire plugin node like this

388
00:27:51,680 --> 00:27:56,032
then an execution node with an id of
web-acceptance-tests

389
00:27:57,312 --> 00:28:01,408
Now we attach it to the test goal -
the one maven runs by default

390
00:28:02,440 --> 00:28:05,960
We configure the execution by excluding
all the unit tests -

391
00:28:05,960 --> 00:28:07,840
no need to run those again

392
00:28:07,840 --> 00:28:11,420
and setting the argline to use
the testDepth of web

393
00:28:11,420 --> 00:28:14,256
with the Cucumber options set to run
only those scenarios tagged

394
00:28:14,260 --> 00:28:16,260
as either high impact or high risk

395
00:28:17,720 --> 00:28:18,300
There

396
00:28:18,900 --> 00:28:21,960
Now when we run `mvn test`
from the command-line

397
00:28:21,960 --> 00:28:26,400
it runs all three layers of our testing pyramid
starting from the bottom up

398
00:28:31,100 --> 00:28:32,380
One last thing:

399
00:28:32,900 --> 00:28:37,800
When we automate web pages, we need to
refer to user interface elements and actions

400
00:28:37,800 --> 00:28:40,320
buttons, links, text, clicks, etc

401
00:28:41,080 --> 00:28:45,540
This is solution domain jargon
we’ve managed to keep out of our scenarios

402
00:28:45,540 --> 00:28:46,540
and that’s good!

403
00:28:47,240 --> 00:28:48,880
But it has to go somewhere

404
00:28:50,300 --> 00:28:53,520
On larger projects, it becomes useful
to create abstractions called

405
00:28:53,520 --> 00:28:56,520
page objects to represent
the things being filled in

406
00:28:56,520 --> 00:28:58,240
clicked, and examined for content

407
00:28:58,960 --> 00:29:03,600
For example, we might have a homepage object
with a method called shout

408
00:29:03,600 --> 00:29:07,460
that encapsulated the calls to interact
with the elements on the web page

409
00:29:07,968 --> 00:29:12,576
This allows you to easily reuse code
and keep it easy to read

410
00:29:13,080 --> 00:29:15,920
You can easily build page objects on your own

411
00:29:15,920 --> 00:29:20,180
but if you’re feeling lazy
Selenium ships with a PageFactory class

412
00:29:20,180 --> 00:29:23,080
that reduces the amount of boilerplate code
you need to write

413
00:29:24,600 --> 00:29:30,460
The page objects pattern is a great fit
for keeping your web automation code tidy

414
00:29:30,460 --> 00:29:33,720
but we strongly recommend that you try to

415
00:29:33,720 --> 00:29:37,560
push as many of your tests
down the pyramid first

416
00:29:38,660 --> 00:29:42,080
You can use page objects together with
a hexagonal architecture pattern

417
00:29:42,080 --> 00:29:44,000
we’ve shown you in this episode

418
00:29:44,000 --> 00:29:46,800
so that when you do need to hit the web UI

419
00:29:46,800 --> 00:29:49,440
you can do that through neat and tidy code

420
00:29:50,200 --> 00:29:53,200
That's it kids, school's out!

421
00:29:53,200 --> 00:29:55,840
Time to step out into the real world

422
00:29:57,120 --> 00:30:02,760
This has been an intense episode
and we’ve thrown a lot of new concepts at you -

423
00:30:02,760 --> 00:30:08,140
the hexagonal architecture, the strategy
pattern and the agile testing pyramid

424
00:30:09,400 --> 00:30:15,280
Please take time to watch this video over
a few times until you understand these concepts

425
00:30:15,280 --> 00:30:18,120
and study the exercises and reflection questions

426
00:30:19,320 --> 00:30:25,020
We want you to remember that acceptance tests
don’t have to be full-stack tests

427
00:30:25,800 --> 00:30:28,620
In fact, it’s often a mistake if they are

428
00:30:29,960 --> 00:30:35,520
Don’t fall into the trap of building yet another
testing ice cream cone for your project

429
00:30:36,040 --> 00:30:39,140
Have developers and testers work side-by-side

430
00:30:39,140 --> 00:30:43,360
to maximize the value you get
from your testing investment

431
00:30:43,360 --> 00:30:47,560
by pushing as many tests
as you can down to the lowest level

432
00:30:48,580 --> 00:30:54,760
The responsibility for the health and wellbeing
of the world’s Cucumber suites rests with you now

433
00:30:55,740 --> 00:30:58,300
Use your knowledge wisely!

434
00:31:00,864 --> 00:31:05,472
If you remember one thing from
the video series, remember this:

435
00:31:06,496 --> 00:31:09,824
The software you write is just a model -

436
00:31:10,840 --> 00:31:14,680
a model of your team's understanding
of the problem domain

437
00:31:15,940 --> 00:31:20,320
The better that understanding is
the better the software will be

438
00:31:21,600 --> 00:31:26,200
Put your effort into understanding
the problem together

439
00:31:26,200 --> 00:31:29,520
and the software will take care of itself

440
00:31:31,840 --> 00:31:34,580
Goodbye from all of us on Cucumber School

441
00:31:34,580 --> 00:31:36,200
and have fun out there!

442
00:31:38,740 --> 00:31:40,700
Captions created by Jayson Smith for Cucumber Ltd.

